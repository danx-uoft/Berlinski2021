---
title: "Voter Fraud Misinformation Reduces Confidence in Electoral Integrity"
author: | 
  | Dan Xu
  | University of Toronto
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2:
    toc: false
bibliography: references.bib
abstract: |
  This project is a replication for "[The Effects of Unsubstantiated Claims of Voter Fraud on Confidence in Elections](https://www.cambridge.org/core/journals/journal-of-experimental-political-science/article/effects-of-unsubstantiated-claims-of-voter-fraud-on-confidence-in-elections/9B4CE6DF2F573955071948B9F649DF7A)". Through a survey experiment with a sample of 4,283 U.S. respondents, @berlinski2021effects find that voter fraud misinformation reduces public confidence in electoral integrity. I performed Ordinary Least-squares regression analyses to replicate their research, and my results show consistency with their findings. However, I also find that voter fraud misinformation increases public confidence in elections if one identifies as a Democrat, suggesting a potential "backfire effect" among partisans when they are constantly exposed to counter-belief fact-checked evidence.   
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo = FALSE, message=FALSE, warning = FALSE}
library(haven)
library(foreign)
library(tidyverse)
library(estimatr)
library(DeclareDesign)
library(gridExtra)
library(ggpubr)
library(stargazer)
```

# Introduction
Illegal election interference and targeted disinformation campaigns on voter fraud have raised concerns among many about the potential for political actors and foreign powers to sabotage the integrity and trustworthiness of democratic institutions. The victory of Joseph R. Biden Jr. in the 2020 presidential election has refueled the discussion of voter fraud between the left and the right in the American society. Donald Trump and his followers publicly accused of illegally voting in the election and demanded investigation into the alleged election fraud. The relationship between conspiracy and election fraud promoted by Trump has drawn attention to political scholars [@pennycook2021examining; @berlinski2021effects]. 

After Biden being elected the President of the United States in 2021, Trump voters have alleged the unfounded claims of voter fraud, arguing that Donald Trump was the actual winner of the election. The aftermath of this event has promoted conspiracy theories that election victory could be easily stolen by local, state and federal agencies and actors. In the 2018 midterm election season, rumor and conspiracy theories regarding potentially fraudulent ballots again circulated among American citizens.  @berlinski2021effects's work examines the corrective effects of voter fraud claims in perceptions of election integrity. By conducting a survey experiment with 4,283 U.S. adults following the 2018 US elections, they find that exposure to misinformation regarding voter fraud reduces confidence in election results. In addition, corrective effects on unfounded voter-fraud allegations are limited, suggesting that fact-checking is not a powerful tool to rectify misconceptions as researchers hypothesized. 

In this paper, I sought out to replicate @berlinski2021effects's work published in 2021. The main goal of this replication is twofold: (1) To re-examine the experimental results in order to testify if exposure to unfounded voter-fraud claims reduces people's confidence in the 2018 elections; (2) To explore other potential variables to explain how misinformation regarding voter fraud reshapes political attitudes and behaviors. The rest of this paper is structured as follows: In the Method section, I re-examined the survey design and treatment conditions; In the Results section, I specified the linear regression model and presented the results generated by the model; In the Discussion section, I discussed conclusions and findings generated by the replication, focusing on the validity and reliability of the research approach. 

# Method
@berlinski2021effects conducted a survey experiment among 4,283 respondents in the United States in December 2018/January 2019. The survey was administered by YouGov and was matched to the demographic characteristics of the U.S. population. 

## Experimental design
The main purpose of the study is to investigate the relationship between election integrity and misinformation about the election results. In the survey experiment, research participants were randomly assigned to one of the following conditions: (1) Placebo: Respondents received a series of non-political tweets; Low dose: Respondents received four tweets alleging voter fraud. (3) High dose: Respondents received the four tweets alleging voter fraud from the low-dose condition and four additional tweets alleging voter fraud. In total, they received eight tweets alleging voter fraud. (4) Low dose + fact-check. Respondents in this treatment group received the four tweets from the low-dose condition alleging voter fraud and four fact-check tweets debunking the four tweets from the low-dose condition. In addition, respondents completed pre-treatment and post-treatment survey questions. 
The survey was conducted immediately after the2018  elections, where several prominent Republicans made unfounded allegations of voter fraud on Twitter. Their Tweets and fact-checks of the unfounded claims were used as the treatment stimuli in the survey experiment. The survey collected demographic information, including education, age, gender, party affiliation, and Trump approval rates. 

# Results
The results for the replication are presented using R and R packages [@R] as follows, 

## Model
The goal of this replication is to re-examine whether exposure to unfounded voter-fraud claims reduces confidence in elections. I estimate linear regression models that include only main effects for experimental conditions as well as models that interact treatment indicators with measures for whether voter-fraud misinformation was congenial for respondents. The models are specified as follows, 

$$
\\Confidence = \beta_0 + \beta_1 Low+\beta_2 High + \beta_3 Correction + Interaction + \epsilon 
$$
where Low refers to low dose (response to the four tweets alleging voter fraud); High refers to high dose (response to the eight tweets alleging voter fraud); Correction refers to fact-checks (response to the four tweets alleging voter fraud and fact-checked claims). There is only one interaction in this model, which is the interaction between party identification/affiliation and the message dosage respondents received. 


```{r echo = FALSE, message=FALSE, warning = FALSE}
#load data 
dat <- readRDS(file = "dat.rds")
```


```{r echo = FALSE, message=FALSE, warning = FALSE,results='hide'}
# Model 1 without interactions
model1 <- lm(zconf_trust ~ tweet4 + tweet8 + tweetcorrect, data = dat)

mod1<-summary(lm_robust(zconf_trust ~ tweet4 + tweet8 + tweetcorrect, data = dat))

# Model 2 with interaction terms 
model2 <- lm(zconf_trust ~ tweet4*dem_leaners + tweet4*independents + 
                    tweet8*dem_leaners + tweet8*independents + 
                    tweetcorrect*dem_leaners + tweetcorrect*independents, data = dat)

mod2<-summary(lm_robust(zconf_trust ~ tweet4*dem_leaners + tweet4*independents + 
                    tweet8*dem_leaners + tweet8*independents + 
                    tweetcorrect*dem_leaners + tweetcorrect*independents, data = dat))
```


```{r table,echo = FALSE, message=FALSE, warning = FALSE,results='asis'}
stargazer(model1,model2, type = "latex",
          header = FALSE,
          # table.placement = "H",
  title = "Regression models",
  column.labels = c("Model without interaction","Model with interaction"),
  dep.var.caption = "Dependent variable ",
  dep.var.labels = "Confidence in election",
covariate.labels=c("Low dose","Democrats","Independents","High dose","Correction","Low dose: Democrats","Low dose: Independents","High dose: Democrats","High dose:Independents","Correction:Democrats","Correction:Independents"),
  keep.stat = c("rsq", "f"),
  single.row = F, # to put coefficients and standard errors on same line
          no.space = F, # to remove the spaces after each line of coefficients
          column.sep.width = "1pt", # to reduce column width
          font.size = "small", # to make font size smaller
  ci=TRUE, 
ci.level=0.95, # confidence level is 95%
          digits=2,
  # float.env = "sidewaystable",
  notes = "The table reports coefficients, p values, and confidence intervals",
  notes.align = "l")
```

\label{tab:table}
The results of the regression models are show in Table \@ref(tab:table). As the results demonstrate, both models produce promising results for predicting the the linear relationship between trust in elections and voter fraud claims. "Low dose" and "High dose" of voter fraud messaging both reduce confidence in electoral integrity (p<0.01). Interestingly, in the "Correction" treatment, where respondents received both "low dose" claims and corrections for such claims, their trust in elections still decreased (p<0.05). This suggests that the effects of fact-checking maybe limited after exposure  to voter fraud misinformation. In the model that contains the interaction term of party identification, the results are similar. Messaging dose and partisanship are still negatively correlated to confidence in elections. The interaction term "party" also effectively predicts the relationship between the dependent and independent variables. The effect of high dose voter fraud misinformation increases by 0.25 for every unit increase if the respondent identifies as Democrats (p<0.001). In addition, the effect of low dose voter fraud misinformation and corrections increases by 0.19 for every unit increase if the respondent identifies as Democrats (p<0.05).

```{r echo = FALSE, message=FALSE, warning = FALSE,results='hide'}
set.seed(888)
N <- 4907 ## Size of the complete dataset with no missingness

## SD of the residuals for model 1
sd.y<-sqrt(mod1$res_var) 

#population <- declare_population(N = N, u = rnorm(N, mean = 0, sd=1.00))
ate_A <- mod1$coefficients[2,1]  # which is the coefficient of tweet4 (ate_A)
ate_B <- mod1$coefficients[3,1]  # which is the coefficient of tweet8 (ate_B)
ate_C <- mod1$coefficients[4,1]# which is the coefficient of tweetcorrect (ate_C)

# Create population
population <- declare_population(N = N, ate_A=ate_A, ate_B=ate_B, ate_C=ate_C, 
                                 u = rnorm(N, mean = 0, sd=sd.y))

# Set up potential outcomes table
potential_outcomes <- declare_potential_outcomes(Y_Z_0 = u,
                                                 Y_Z_1 = ate_A + u,
                                                 Y_Z_2 = ate_B + u,
                                                 Y_Z_3 = ate_C+ u
                                                 )

## Test if potential outcomes set up correctly -- should all be zero
j<-potential_outcomes(population())
mean(j$Y_Z_1-j$Y_Z_0)-ate_A
mean(j$Y_Z_2-j$Y_Z_0)-ate_B
mean(j$Y_Z_3-j$Y_Z_0)-ate_C

## Randomization and estimand declaration
randomization<-declare_assignment(conditions=0:3,legacy = TRUE)
inquiry <- declare_inquiry(ate_1 = mean(Y_Z_1-Y_Z_0), 
                              ate_2 = mean(Y_Z_2-Y_Z_0), 
                               ate_3 = mean(Y_Z_3-Y_Z_0))

## Reveal based on randomization                                                  
reveal<-declare_reveal(Y, Z)

## Estimate the model
estimator<-declare_estimator(
        Y ~ as.factor(Z),
        model = lm_robust,
        term=c("as.factor(Z)1", "as.factor(Z)2", "as.factor(Z)3"),
        inquiry = c("ate_1", "ate_2", "ate_3"))

## Declare the complete design and analysis
design<-population + potential_outcomes + inquiry+ randomization  + reveal+estimator

## Test simulation
# simulation <- simulate_design(design, sims = 5)
# simulation
```

```{r figure, echo = FALSE, message=FALSE, warning = FALSE,results='hide'}
## Make MDE diagnostics for each coefficient
redesign <- redesign(design, 
                     ate_A = seq(0, -0.25, by=-0.01))
redesign$design_1
new_diagnosis <- diagnose_design(redesign, 
                                 diagnosands = declare_diagnosands(power = mean(p.value<.05)), 
                                 sims = 100)

results_ATE1<-
  new_diagnosis$diagnosands_df %>% 
  filter(inquiry =="ate_1")

## Second coef
redesign <- redesign(design, 
                     ate_B = seq(0, -0.25, by=-0.01))

new_diagnosis <- diagnose_design(redesign, 
                                 diagnosands = declare_diagnosands(power = mean(p.value<.05)), 
                                 sims = 100)

results_ATE2<-
  new_diagnosis$diagnosands_df %>% 
  filter(inquiry=="ate_2")

## Third coef
redesign <- redesign(design, 
                     ate_C = seq(0, -0.25, by=-0.01))
new_diagnosis <- diagnose_design(redesign, 
                                 diagnosands = declare_diagnosands(power = mean(p.value<.05)), 
                                 sims = 100)

results_ATE3<-
  new_diagnosis$diagnosands_df %>% 
  filter(inquiry=="ate_3")


results_ATE1a <-
  results_ATE1 %>%
  mutate(ate = ate_A) %>% 
  select(inquiry, power, ate)

 results_ATE1a$inquiry <- "Low Dose" 
  
results_ATE2a <-
  results_ATE2 %>%
  mutate(ate = ate_B)%>% 
  select(inquiry, power, ate)

 results_ATE2a$inquiry <- "High Dose" 

results_ATE3a <-
  results_ATE3 %>%
  mutate(ate = ate_C)%>% 
  select(inquiry, power, ate)

 results_ATE3a$inquiry <- "Low Dose + Correction" 

all_bind <- rbind(results_ATE1a,results_ATE2a,results_ATE3a)

## all 
all_bind %>% 
  rename(Condition = inquiry) %>% 
   ggplot(aes(ate, power,color=Condition))+
  geom_point()+
  geom_line()+
  geom_hline(yintercept=.8, lty=2)+
  # geom_vline(xintercept= ate, lty=3) +
  xlab("ATE") +  ylab("Power") + 
  theme(labs(title = NULL)) + 
  scale_shape_identity() +
  theme_bw()

all_bind

```

\label{fig:figure}
Performing statistical power analysis and sample size estimation is an important aspect of experimental design. To check the robustness of the experimental design, I further conducted power analyses to determine the effects of the given size of the sample. As shown in Figure \ref{fig:figure}, the simulations show that the sample is powered to detect main effects of larger samples.The design is sufficiently powered to detect an estimand similar in magnitude to the estimate we report for coefficients in Table \@ref(tab:table).


# Discussion  
It is widely acknowledged that the system of government and our liberty depend on free and fair elections. Therefore, it is an urgent task for social scientists to investigate the potential effects of misinformation on political attitudes, behaviors, and voting behaviors. @berlinski2021effects's studies is one of the prominent works to tap into the relationship between public trust and voter fraud misinformation. 

The results generated by this replication are consistent with the original study conducted by @berlinski2021effects. In general, exposure to voter fraud misinformation reduces people's confidence in elections. Specifically, regression results show that respondents exposed to either low or high doses of voter-fraud claims showed less confidence in elections than those in the placebo condition, where respondents did not receive any political tweets. However, it is also noted that fact-checks do not reduce misconceptions of voter fraud, this worrying finding suggests the limited effects of fact-checking. After exposure to misinformation in relation to voter fraud, public trust in the election process will still be negatively influenced even they are presented with corrective information. 

In the model including the interaction term, we can observe the interaction effects between party identification and doses of exposure to allegations of voter. For the high dose treatment condition, exposure to misinformation about voter fraud increases confidence in elections if they identify as Democrats. However, the same effect was not observed for the Republicans. This finding seems to contradict our prior assumption because it implies that the more misinformation Democrats receive, the more likely they gain trust in elections. The theory of "Backfire Effect" may be a framework to explore for an explanation for such observations. Accordingly, the backfire effect theory suggests that people reinforce their prior beliefs when they are constantly expose to misinformation [@swire2020searching]. Future work would address such a limitation by testing if partisanship congeniality plays a role in misinformation acceptance and denial when they are constantly receiving counter-belief evidence. 

Furthermore, I recommend conducting a follow-up study to see if voters would be less likely to participate in politics, or cast their votes when their confidence in elections reduces because of voter fraud misinformation. 

# References
